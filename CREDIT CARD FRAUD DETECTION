{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1399887,"sourceType":"datasetVersion","datasetId":817870}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#  -> Now: CREDIT CARD FRAUD DETECTION notebook\n\nimport os\nimport glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\n# 1. Load dataset (auto-detect common paths)\n\npossible_paths = [\n    '/kaggle/input/creditcardfraud/creditcard.csv',\n    '/kaggle/input/creditcard/creditcard.csv',\n    '/kaggle/input/credit-card-fraud-detection/creditcard.csv',\n    'creditcard.csv',\n]\n\ncsv_path = None\nfor p in possible_paths:\n    if os.path.exists(p):\n        csv_path = p\n        break\n\n# fallback: search any csv with 'credit' or 'fraud' in name under /kaggle/input\nif csv_path is None and os.path.exists('/kaggle/input'):\n    all_csvs = glob.glob('/kaggle/input/**/*.csv', recursive=True) + glob.glob('/kaggle/input/*.csv')\n    for f in all_csvs:\n        fname = os.path.basename(f).lower()\n        if 'credit' in fname or 'fraud' in fname:\n            csv_path = f\n            break\n\nif csv_path is None:\n    raise FileNotFoundError(\"creditcard.csv not found. Upload dataset to Kaggle and re-run, or change path in the notebook.\")\n\nprint(\"Using dataset:\", csv_path)\ndf = pd.read_csv(csv_path)\nprint(\"Dataset shape:\", df.shape)\ndf.head()\n\n# 2. Quick EDA\n\nprint(\"\\nColumns:\", df.columns.tolist())\nprint(\"\\nMissing values per column:\\n\", df.isnull().sum())\n\n# target distribution\nif 'Class' in df.columns:\n    target_col = 'Class'\nelif 'fraud' in df.columns.str.lower():\n    # try find target-like column\n    for c in df.columns:\n        if c.lower() in ['class','fraud','isfraud','label','target']:\n            target_col = c\n            break\nelse:\n    raise ValueError(\"Target column not found. Expected 'Class' (0 = normal, 1 = fraud).\")\n\nprint(f\"\\nTarget column used: {target_col}\")\nprint(df[target_col].value_counts())\nprint(\"\\nFraud ratio: {:.6f}\".format(df[target_col].mean()))\n\n# basic plots\nplt.figure(figsize=(6,4))\nsns.countplot(x=target_col, data=df)\nplt.title('Class Distribution (0 = normal, 1 = fraud)')\nplt.savefig('class_distribution.png', bbox_inches='tight', dpi=200)\nplt.show()\n\n# Amount distribution\nplt.figure(figsize=(8,4))\nsns.histplot(df['Amount'], bins=50, kde=True)\nplt.title('Transaction Amount Distribution')\nplt.savefig('amount_distribution.png', bbox_inches='tight', dpi=200)\nplt.show()\n\n# 3. Preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# copy to avoid changing original\ndata = df.copy()\n\n# features and target\nX = data.drop(columns=[target_col])\ny = data[target_col]\n\n# If Time feature present, optionally drop or use\nif 'Time' in X.columns:\n    # many approaches: drop Time or transform; for simplicity drop it\n    X = X.drop(columns=['Time'])\n\n# Scale Amount (and any other numeric non-V features)\nscaler = StandardScaler()\nif 'Amount' in X.columns:\n    X['Amount_scaled'] = scaler.fit_transform(X[['Amount']])\n    X = X.drop(columns=['Amount'])\n    \nprint(\"Feature shape:\", X.shape)\n\n# Train-test split (stratify due to imbalance)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n)\nprint(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n\n# 4. Handle class imbalance (SMOTE)\n\ntry:\n    from imblearn.over_sampling import SMOTE\n    smote = SMOTE(random_state=RANDOM_STATE, n_jobs=-1)\n    X_res, y_res = smote.fit_resample(X_train, y_train)\n    print(\"After SMOTE, counts:\", pd.Series(y_res).value_counts().to_dict())\nexcept Exception as e:\n    print(\"imblearn.SMOTE not available or failed:\", e)\n    print(\"Proceeding without SMOTE (use class_weight or sample balancing).\")\n    X_res, y_res = X_train, y_train\n    \n# 5. Modeling: Train multiple models\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\nimport joblib\n\nmodels = {}\n\n# 5.1 Logistic Regression (with balanced class weight if SMOTE not used)\nlr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, n_jobs=-1)\nlr.fit(X_res, y_res)\nmodels['LogisticRegression'] = lr\n\n# 5.2 Random Forest\nrf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\nrf.fit(X_res, y_res)\nmodels['RandomForest'] = rf\n\n# 5.3 XGBoost (if available)\ntry:\n    import xgboost as xgb\n    xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE, n_jobs=-1)\n    xgb_clf.fit(X_res, y_res)\n    models['XGBoost'] = xgb_clf\nexcept Exception as e:\n    print(\"XGBoost not available or failed to train:\", e)\n\n# 6. Evaluation on Test Set\n\nresults = []\ny_test_array = np.array(y_test)\n\nfor name, model in models.items():\n    y_pred = model.predict(X_test)\n    # probability if available\n    try:\n        y_proba = model.predict_proba(X_test)[:,1]\n    except:\n        y_proba = None\n    \n    acc = accuracy_score(y_test_array, y_pred)\n    prec = precision_score(y_test_array, y_pred, zero_division=0)\n    rec = recall_score(y_test_array, y_pred)\n    f1 = f1_score(y_test_array, y_pred)\n    roc = roc_auc_score(y_test_array, y_proba) if y_proba is not None else None\n    \n    print(f\"\\n=== {name} ===\")\n    print(\"Accuracy: {:.4f}  Precision: {:.4f}  Recall: {:.4f}  F1: {:.4f}  ROC-AUC: {}\".format(\n        acc, prec, rec, f1, (f'{roc:.4f}' if roc is not None else 'N/A')\n    ))\n    print(classification_report(y_test_array, y_pred, digits=4))\n    \n    cm = confusion_matrix(y_test_array, y_pred)\n    plt.figure(figsize=(5,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title(f'Confusion Matrix - {name}')\n    plt.savefig(f'confusion_{name}.png', bbox_inches='tight', dpi=200)\n    plt.show()\n    \n    results.append({\n        'model': name, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'roc_auc': roc\n    })\n    \n    # save model\n    joblib.dump(model, f'{name}_model.joblib')\n\nresults_df = pd.DataFrame(results).sort_values(by='f1', ascending=False)\nprint(\"\\nModel comparison:\\n\", results_df)\n\n# 7. Choose best model and output predictions csv\nbest_model_name = results_df.iloc[0]['model']\nbest_model = models[best_model_name]\nprint(\"\\nBest model chosen:\", best_model_name)\n\n# Predict and save detailed test results\ntry:\n    test_proba = best_model.predict_proba(X_test)[:,1]\nexcept:\n    test_proba = None\n\ntest_pred = best_model.predict(X_test)\noutput_df = X_test.copy()\noutput_df['TrueClass'] = y_test\noutput_df['PredictedClass'] = test_pred\nif test_proba is not None:\n    output_df['PredictedProb'] = test_proba\n\noutput_csv = 'fraud_predictions_test.csv'\noutput_df.to_csv(output_csv, index=False)\nprint(\"Saved predictions to:\", output_csv)\n\n# 8. Additional evaluation: Precision-Recall curve & ROC\n\nfrom sklearn.metrics import precision_recall_curve, auc, roc_curve\n\nif test_proba is not None:\n    precision, recall, _ = precision_recall_curve(y_test_array, test_proba)\n    pr_auc = auc(recall, precision)\n    fpr, tpr, _ = roc_curve(y_test_array, test_proba)\n    roc_auc_val = auc(fpr, tpr)\n    \n    plt.figure(figsize=(6,4))\n    plt.plot(recall, precision)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(f'Precision-Recall curve (AUC={pr_auc:.4f})')\n    plt.savefig('precision_recall_curve.png', bbox_inches='tight', dpi=200)\n    plt.show()\n    \n    plt.figure(figsize=(6,4))\n    plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc_val:.4f}')\n    plt.plot([0,1],[0,1],'--', linewidth=0.7)\n    plt.xlabel('FPR')\n    plt.ylabel('TPR')\n    plt.title('ROC Curve')\n    plt.legend()\n    plt.savefig('roc_curve.png', bbox_inches='tight', dpi=200)\n    plt.show()\n\n# 9. Feature importance (for tree models)\nif 'RandomForest' in models:\n    rf_model = models['RandomForest']\n    importances = rf_model.feature_importances_\n    feat_names = X.columns\n    feat_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)[:20]\n    plt.figure(figsize=(8,6))\n    sns.barplot(x=feat_imp.values, y=feat_imp.index)\n    plt.title('Top 20 Feature Importances - RandomForest')\n    plt.savefig('feature_importance_rf.png', bbox_inches='tight', dpi=200)\n    plt.show()\n\n# 10. Summary of files created\nprint(\"\\nFiles generated in working directory:\")\nfor fname in ['class_distribution.png','amount_distribution.png','confusion_LogisticRegression.png',\n              'confusion_RandomForest.png','fraud_predictions_test.csv','precision_recall_curve.png',\n              'roc_curve.png','feature_importance_rf.png']:\n    if os.path.exists(fname):\n        print(\" -\", fname)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T08:16:17.004680Z","iopub.execute_input":"2025-11-09T08:16:17.004987Z","iopub.status.idle":"2025-11-09T08:16:25.938982Z","shell.execute_reply.started":"2025-11-09T08:16:17.004961Z","shell.execute_reply":"2025-11-09T08:16:25.937462Z"}},"outputs":[{"name":"stdout","text":"Using dataset: /kaggle/input/fraud-detection/fraudTest.csv\nDataset shape: (555719, 23)\n\nColumns: ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n\nMissing values per column:\n Unnamed: 0               0\ntrans_date_trans_time    0\ncc_num                   0\nmerchant                 0\ncategory                 0\namt                      0\nfirst                    0\nlast                     0\ngender                   0\nstreet                   0\ncity                     0\nstate                    0\nzip                      0\nlat                      0\nlong                     0\ncity_pop                 0\njob                      0\ndob                      0\ntrans_num                0\nunix_time                0\nmerch_lat                0\nmerch_long               0\nis_fraud                 0\ndtype: int64\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3488006360.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target column not found. Expected 'Class' (0 = normal, 1 = fraud).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTarget column used: {target_col}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target column not found. Expected 'Class' (0 = normal, 1 = fraud)."],"ename":"ValueError","evalue":"Target column not found. Expected 'Class' (0 = normal, 1 = fraud).","output_type":"error"}],"execution_count":1}]}
